{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q-Drn_ZSEzQ4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import keras.preprocessing.image \n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,  GlobalMaxPooling2D\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input\n",
    "import csv\n",
    "import pandas as pd   \n",
    "import os\n",
    "import h5py\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2W42HfxLUoV0"
   },
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "WANTED_BANDS = [3, 2, 1]\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS, NUM_OG_BANDS = (64, 64, len(WANTED_BANDS), 13) \n",
    "MODEL_NAME = \"CNN-({})input-({}, {}, {})\".format(\"Resnet50\", IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS)\n",
    "PATH = \"/atlas/u/{}/data/kiln-scaling/models/{}/\".format(sys.argv[0], MODEL_NAME) \n",
    "DATA_PATH = \"/atlas/u/mhelabd/data/kiln-scaling/tiles/\"\n",
    "MODEL_WEIGHTS_PATH = PATH + \"weights/\"\n",
    "MODEL_HISTORY_PATH = PATH + \"history/\"\n",
    "VERBOSE = True\n",
    "BALANCE_DATASET = True\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_h5(preprocess=False, verbose=VERBOSE, balance_dataset=BALANCE_DATASET):\n",
    "    X, y = [], []\n",
    "    for i, filename in enumerate(os.listdir(DATA_PATH)):\n",
    "        print(\"extracting: \",filename) \n",
    "        with h5py.File(DATA_PATH + filename, \"r\") as f:\n",
    "            if i == 0:\n",
    "                X = np.array(f[\"images\"][()])\\\n",
    "                    .reshape((-1, NUM_OG_BANDS, IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "                X = np.moveaxis(X, 1, -1)[:, :, :, WANTED_BANDS]\n",
    "                y = np.array(f[\"labels\"][()])\n",
    "            else:\n",
    "                x_i = np.array(f[\"images\"][()])\\\n",
    "                    .reshape((-1, NUM_OG_BANDS, IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "                x_i = np.moveaxis(x_i, 1, -1)[:, :, :, WANTED_BANDS]\n",
    "                X = np.concatenate((X, x_i))\n",
    "                y_i = np.array(f[\"labels\"][()])\n",
    "                y = np.concatenate((y, y_i))\n",
    "\n",
    "        if balance_dataset:\n",
    "            #since y = 1 is always less\n",
    "            n= y[y==1].shape[0]\n",
    "            mask = np.hstack([np.random.choice(np.where(y == l)[0], n, replace=False)\n",
    "                              for l in np.unique(y)])\n",
    "            X = X[mask]\n",
    "            y = y[mask]\n",
    "        \n",
    "    if preprocess:\n",
    "        X = preprocess_input(X)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"x shape: \", X.shape)\n",
    "        print(\"y shape: \", y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xIiihb61UoV2"
   },
   "outputs": [],
   "source": [
    "def load_data_from_csv(preprocess=True, verbose=VERBOSE):\n",
    "    for i in range(24):\n",
    "        if i == 0:\n",
    "            x_pos = np.loadtxt(DATA_PATH + 'pos_x_examples'+ str(i)+'.csv', delimiter=',')\\\n",
    "                .reshape((-1, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS))\n",
    "            x_neg = np.loadtxt(DATA_PATH + 'neg_x_examples'+ str(i)+'.csv', delimiter=',')\\\n",
    "                .reshape((-1, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS))\n",
    "        else:\n",
    "            x_pos_i = np.loadtxt(DATA_PATH + 'pos_x_examples'+ str(i)+'.csv', delimiter=',')\\\n",
    "                .reshape((-1, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS))\n",
    "            x_pos = np.concatenate((x_pos, x_pos_i))\n",
    "            x_neg_i = np.loadtxt(DATA_PATH + 'neg_x_examples'+ str(i)+'.csv', delimiter=',')\\\n",
    "                .reshape((-1, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS))\n",
    "            x_neg = np.concatenate((x_neg, x_neg_i))\n",
    "    if verbose:\n",
    "        print(\"x_pos.shape: \", x_pos.shape)\n",
    "        print(\"x_neg.shape: \", x_neg.shape)\n",
    "    if preprocess:\n",
    "        x_pos = preprocess_input(x_pos)\n",
    "        x_neg = preprocess_input(x_neg)\n",
    "\n",
    "    X = np.concatenate((x_pos, x_neg))    \n",
    "    # y is a vector of ones (kilns present) and zeros (kilns absent)\n",
    "    y = np.concatenate((np.ones(len(x_pos)), np.zeros(len(x_neg) ) )).reshape(-1, 1)\n",
    "    if verbose:\n",
    "        print(\"x shape: \", X.shape)\n",
    "        print(\"y shape: \", y.shape)\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w9ga7Zr0UoV4"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, train_percent=0.7, val_percent=0.1, test_percent=0.2):\n",
    "    assert train_percent + val_percent + test_percent == 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percent, random_state=RANDOM_STATE)\n",
    "    updated_val_precent = val_percent/(1 - test_percent)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=updated_val_precent, random_state=RANDOM_STATE)\n",
    "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9pAPcOYFUoV5"
   },
   "outputs": [],
   "source": [
    "def make_model(weights=\"imagenet\", \n",
    "               include_top=False, \n",
    "               load_weights=None, # path of weights\n",
    "               loss=keras.losses.binary_crossentropy, \n",
    "               optimizer=keras.optimizers.Adam(), \n",
    "               metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)]):\n",
    "    \n",
    "    image_input = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_BANDS))\n",
    "    base_model = ResNet50(include_top=include_top, weights=weights, input_tensor=image_input, classes=2)\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(1024,activation='relu')(x) \n",
    "    x = Dense(1024,activation='relu')(x) \n",
    "    x = Dense(512,activation='relu')(x) \n",
    "    x = Dense(1, activation= 'sigmoid')(x)\n",
    "    model = Model(inputs = base_model.input, outputs = x)\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    if load_weights:\n",
    "        model.load_weights(load_weights)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VUTRTXc9UoV6"
   },
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                X_train, \n",
    "                y_train,\n",
    "                X_val,\n",
    "                y_val,\n",
    "                trial_name, \n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                multiprocessing=True, \n",
    "                early_stopping=False, \n",
    "                save_history=True):\n",
    "    \n",
    "    callbacks = []\n",
    "    \n",
    "    if early_stopping:\n",
    "        early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "        callbacks.append(early_stop)\n",
    "    checkpoint_file = MODEL_WEIGHTS_PATH + \"{}.h5\".format(trial_name)\n",
    "    checkpoint = ModelCheckpoint(checkpoint_file, \n",
    "                                  save_weights_only=True,\n",
    "                                  monitor='val_accuracy',\n",
    "                                  mode='max',\n",
    "                                  save_best_only=True)\n",
    "    callbacks.append(checkpoint)                        \n",
    "    \n",
    "    history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        use_multiprocessing=multiprocessing, \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        callbacks=callbacks)\n",
    "    if save_history:\n",
    "        with open(MODEL_HISTORY_PATH + trial_name, 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RSMc6P_5Yeqp"
   },
   "outputs": [],
   "source": [
    "def graph_model_performance(history):\n",
    "  # IF METRICS ARE UPDATED, YOU MUST UPDATE THIS\n",
    "  # summarize history for accuracy\n",
    "  plt.plot(list(history['binary_accuracy']))\n",
    "  plt.plot(list(history['val_binary_accuracy']))\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()\n",
    "  # summarize history for loss\n",
    "  plt.plot(list(history['loss']))\n",
    "  plt.plot(list(history['val_loss']))\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UkdA8TdxUoV8"
   },
   "outputs": [],
   "source": [
    "def print_images(x):\n",
    "  normalized_x = x/np.max(x)\n",
    "  plt.imshow(normalized_x)\n",
    "  plt.show()\n",
    "def evaluate_dataset(model, X, y, threshold=0.5, pictures=True):\n",
    "  # Evaluate the model on the test data using `evaluate`\n",
    "  results = model.evaluate(X, y, batch_size=128)\n",
    "  print(dict(zip(model.metrics_names, results)))\n",
    "  y_pred = model.predict(X) > threshold\n",
    "  print(tf.math.confusion_matrix(y.reshape(-1), y_pred.reshape(-1)))\n",
    "  if pictures:\n",
    "    print(\"Generating three false positives...\")\n",
    "    false_positives = np.logical_and(y != y_pred, y_pred == 1)\n",
    "    X_fp = X[false_positives.reshape(-1), :, :]\n",
    "    for i in range(3):\n",
    "      randi = np.random.randint(0, len(X_fp))\n",
    "      print_images(X_fp[randi])\n",
    "    print(\"Generating three false negatives...\")\n",
    "    false_negatives = np.logical_and(y != y_pred, y_pred == 0)\n",
    "    X_fn = X[false_negatives.reshape(-1), :, :]\n",
    "    for i in range(3):\n",
    "      randi = np.random.randint(0, len(X_fn))\n",
    "      print_images(X_fn[randi])\n",
    "def evaluate_model(model, X_train, X_val, X_test, y_train, y_val, y_test, threshold=0.5, pictures=True):\n",
    "  print(\"Evaluating Training data: \")\n",
    "  evaluate_dataset(model, X_train, y_train, threshold=threshold, pictures=pictures)\n",
    "  \n",
    "  print(\"Evaluating Validation data: \")\n",
    "  evaluate_dataset(model, X_val, y_val, threshold=threshold, pictures=pictures)\n",
    "\n",
    "  print(\"Evaluating Training data: \")\n",
    "  evaluate_dataset(model, X_test, y_test, threshold=threshold, pictures=pictures)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting:  examples_9.hdf5\n",
      "extracting:  examples_30.hdf5\n",
      "extracting:  examples_19.hdf5\n",
      "extracting:  examples_28.hdf5\n",
      "extracting:  examples_24.hdf5\n",
      "extracting:  examples_15.hdf5\n",
      "extracting:  examples_5.hdf5\n",
      "extracting:  examples_11.hdf5\n",
      "extracting:  examples_20.hdf5\n",
      "extracting:  examples_1.hdf5\n",
      "extracting:  examples_25.hdf5\n",
      "extracting:  examples_14.hdf5\n",
      "extracting:  examples_4.hdf5\n",
      "extracting:  examples_10.hdf5\n",
      "extracting:  examples_21.hdf5\n",
      "extracting:  examples_0.hdf5\n",
      "extracting:  examples_8.hdf5\n",
      "extracting:  examples_31.hdf5\n",
      "extracting:  examples_18.hdf5\n",
      "extracting:  examples_29.hdf5\n",
      "extracting:  examples_27.hdf5\n",
      "extracting:  examples_16.hdf5\n",
      "extracting:  examples_6.hdf5\n",
      "extracting:  examples_12.hdf5\n",
      "extracting:  examples_23.hdf5\n",
      "extracting:  examples_2.hdf5\n",
      "extracting:  examples_33.hdf5\n",
      "extracting:  examples_32.hdf5\n",
      "extracting:  examples_26.hdf5\n",
      "extracting:  examples_17.hdf5\n",
      "extracting:  examples_7.hdf5\n",
      "extracting:  examples_13.hdf5\n",
      "extracting:  examples_22.hdf5\n",
      "extracting:  examples_3.hdf5\n",
      "x shape:  (2392, 64, 64, 3)\n",
      "y shape:  (2392, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data_from_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting:  examples_9.hdf5\n",
      "extracting:  examples_30.hdf5\n",
      "extracting:  examples_19.hdf5\n",
      "extracting:  examples_28.hdf5\n",
      "extracting:  examples_24.hdf5\n",
      "extracting:  examples_15.hdf5\n",
      "extracting:  examples_5.hdf5\n",
      "extracting:  examples_11.hdf5\n",
      "extracting:  examples_20.hdf5\n",
      "extracting:  examples_1.hdf5\n",
      "extracting:  examples_25.hdf5\n",
      "extracting:  examples_14.hdf5\n",
      "extracting:  examples_4.hdf5\n",
      "extracting:  examples_10.hdf5\n",
      "extracting:  examples_21.hdf5\n",
      "extracting:  examples_0.hdf5\n",
      "extracting:  examples_8.hdf5\n",
      "extracting:  examples_31.hdf5\n",
      "extracting:  examples_18.hdf5\n",
      "extracting:  examples_29.hdf5\n",
      "extracting:  examples_27.hdf5\n",
      "extracting:  examples_16.hdf5\n",
      "extracting:  examples_6.hdf5\n",
      "extracting:  examples_12.hdf5\n",
      "extracting:  examples_23.hdf5\n",
      "extracting:  examples_2.hdf5\n",
      "extracting:  examples_33.hdf5\n",
      "extracting:  examples_32.hdf5\n",
      "extracting:  examples_26.hdf5\n",
      "extracting:  examples_17.hdf5\n",
      "extracting:  examples_7.hdf5\n",
      "extracting:  examples_13.hdf5\n",
      "extracting:  examples_22.hdf5\n",
      "extracting:  examples_3.hdf5\n"
     ]
    }
   ],
   "source": [
    "    for i, filename in enumerate(os.listdir(DATA_PATH)):\n",
    "        print(\"extracting: \",filename) \n",
    "        with h5py.File(DATA_PATH + filename, \"r\") as f:\n",
    "            if i == 0:\n",
    "                X = np.array(f[\"images\"][()])\\\n",
    "                    .reshape((-1, NUM_OG_BANDS, IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "                X = np.moveaxis(X, 1, -1)[:, :, :, WANTED_BANDS]\n",
    "                y = np.array(f[\"labels\"][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3,   5,  88,  99, 116, 182, 186, 190, 198, 209, 274, 330, 369,\n",
       "        390, 481, 489, 645, 648, 679, 692, 700, 740, 846, 868, 915, 994,\n",
       "        997]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ca02f8358>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[3]/np.max(X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZS4PBUqJXWKp",
    "outputId": "aabc3d74-7b5a-45d5-9935-7ca0c3d43364",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 2.5422 - binary_accuracy: 0.4909WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 2.5422 - binary_accuracy: 0.4909 - val_loss: 0.6935 - val_binary_accuracy: 0.4875\n",
      "Epoch 2/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6939 - binary_accuracy: 0.4973WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6939 - binary_accuracy: 0.4973 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 3/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6936 - binary_accuracy: 0.4949WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6936 - binary_accuracy: 0.4949 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 4/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6956 - binary_accuracy: 0.4913WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6956 - binary_accuracy: 0.4913 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 5/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6934 - binary_accuracy: 0.4913WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6934 - binary_accuracy: 0.4913 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 6/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6937 - binary_accuracy: 0.4931WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6937 - binary_accuracy: 0.4931 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 7/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 8/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4830WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4830 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 9/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 10/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6929 - val_binary_accuracy: 0.5125\n",
      "Epoch 11/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 12/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 13/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 14/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4608WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4608 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 15/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 16/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 17/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5009WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5009 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 18/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4710WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4710 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 19/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4842WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4842 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 20/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4907 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 21/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4913WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4913 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 22/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4836WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4836 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 23/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4866WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4866 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 24/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 25/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 27/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 28/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 29/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 30/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4997 - val_loss: 0.6935 - val_binary_accuracy: 0.4875\n",
      "Epoch 31/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 32/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4692WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6933 - binary_accuracy: 0.4692 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 33/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 34/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 35/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 36/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 37/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 38/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 39/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 40/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 41/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 42/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 43/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4812WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4812 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 44/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5069WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6931 - binary_accuracy: 0.5069 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 45/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 46/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 47/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 48/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 49/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 50/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 52/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6934 - val_binary_accuracy: 0.4875\n",
      "Epoch 53/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 54/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 55/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 56/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4740WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4740 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 57/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 58/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4883WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4883 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 59/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4925WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4925 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 60/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5015WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5015 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 61/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4722WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4722 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 62/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 63/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 64/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 65/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4937WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4937 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 66/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 67/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 68/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 69/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 70/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 71/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 72/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4770 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 73/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4895WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4895 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 74/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 75/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6931 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 77/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 78/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 79/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4937WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4937 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 80/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4967WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4967 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 81/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4913WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4913 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 82/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 83/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4943WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4943 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 84/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 85/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 86/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 87/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 88/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 89/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 90/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4973WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4973 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 91/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 92/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4967WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4967 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 93/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 94/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4788WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4788 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 95/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5081WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.5081 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 96/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 97/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 98/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4883WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4883 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 99/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4985WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4985 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 100/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4907 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 102/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 103/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 104/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4806WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4806 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 105/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 106/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4907 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 107/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4961WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4961 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 108/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 109/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 110/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 111/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4770 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 112/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4967WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4967 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 113/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4985WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4985 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 114/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 115/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 116/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 117/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 118/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 119/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 120/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 121/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 122/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 123/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5015WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5015 - val_loss: 0.6931 - val_binary_accuracy: 0.4875\n",
      "Epoch 124/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4734WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4734 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 125/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4871WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4871 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4794WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4794 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 127/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 128/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 129/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5063WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.5063 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 130/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 131/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 132/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.4973WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.4973 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 133/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 134/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 135/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 136/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 137/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4770 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 138/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4680WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4680 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 139/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4860WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4860 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 140/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5045WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5045 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 141/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 142/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 143/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 144/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 145/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4979WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4979 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 146/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 147/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6933 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 148/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 149/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 150/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 152/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 153/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 154/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4889 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 155/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 156/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 157/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 158/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 159/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 160/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 161/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 162/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 163/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 164/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 165/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 166/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 167/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 168/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4794WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4794 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 169/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 170/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 171/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 172/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 173/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 174/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 175/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 177/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 178/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6931 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 179/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 180/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 181/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 182/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 183/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 184/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 185/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5021WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5021 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 186/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 187/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 188/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 189/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 190/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 191/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4740WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4740 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 192/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 193/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4830WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4830 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 194/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4991WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4991 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 195/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 196/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5021WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5021 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 197/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 198/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4961WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4961 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 199/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 200/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.4997 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 202/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 203/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 204/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 205/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4961WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4961 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 206/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 207/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 208/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 209/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6931 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 210/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4907 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 211/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 212/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 213/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5003WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.5003 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 214/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4758WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6933 - binary_accuracy: 0.4758 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 215/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4919WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4919 - val_loss: 0.6931 - val_binary_accuracy: 0.5125\n",
      "Epoch 216/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4901WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4901 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 217/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 218/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 219/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 220/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 221/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 222/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 223/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 224/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 225/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 227/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 228/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 229/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6933 - val_binary_accuracy: 0.4875\n",
      "Epoch 230/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 231/4000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 0.6932 - binary_accuracy: 0.4997 - val_loss: 0.6932 - val_binary_accuracy: 0.4875\n",
      "Epoch 232/4000\n",
      "11/27 [===========>..................] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.4830"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, train_percent=0.7, val_percent=0.1, test_percent=0.2)\n",
    "model = make_model()\n",
    "model, history = train_model(model, X_train, y_train, X_val, y_val, \"trial_1_epoch_40\", epochs=4000, save_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "IArfjhZkmAPb",
    "outputId": "fea34a25-d2a0-49f8-a061-6dbacfffd3ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd1UlEQVR4nO3df3xcdZ3v8dc70wmT9Af0F2xpXVu9rtbW0JZQURTL4iIUEYUu1AV34Spd0b2Cu9cF3R/o7vVe7r3KZf0F4orobi8sW0TQBV1REH0gSIullB8KKixpob+wpaU/k3z2j3OSTpJJmoZOZpLv+/l45JGZc87M+cxJMu98v98536OIwMzM0tVQ6wLMzKy2HARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJgNkqQbJP2PQW77tKS3v9znMRsODgIzs8Q5CMzMEucgsFEl75L5mKQ1kl6S9FVJR0m6U9J2SXdJmli2/bskPSppq6R7JM0uWzdf0kP54/4FKPXa1zslrc4fe5+kliHWfJGkpyS9IOl2SUfnyyXp/0naKGlb/prm5usWS3osr22dpP8+pANmhoPARqezgT8Afg84A7gT+AQwhex3/iMAkn4PuBG4FJgK3AF8W1KjpEbgW8A/AZOAf82fl/yxC4DrgT8FJgNfBm6XdNjBFCrp94H/BZwDTAOeAW7KV58CnJi/jiOAc4Et+bqvAn8aEeOBucAPD2a/ZuUcBDYafT4iNkTEOuDHwAMR8fOI2APcCszPtzsX+LeI+H5E7AM+AzQBbwaOB4rA1RGxLyJWAA+W7eMi4MsR8UBEdETE14E9+eMOxnnA9RHxUF7fx4E3SZoJ7APGA68DFBGPR8Rz+eP2Aa+XNCEifhsRDx3kfs26OQhsNNpQdntXhfvj8ttHk/0HDkBEdALPAtPzdeui56yMz5TdfiXwF3m30FZJW4FX5I87GL1r2EH2X//0iPgh8AXgi8AGSddJmpBvejawGHhG0o8kvekg92vWzUFgKVtP9oYOZH3yZG/m64DngOn5si6/W3b7WeDTEXFE2VdzRNz4MmsYS9bVtA4gIj4XEccCc8i6iD6WL38wIs4EjiTrwrr5IPdr1s1BYCm7GThd0smSisBfkHXv3Af8FGgHPiJpjKSzgIVlj/0K8EFJb8wHdcdKOl3S+IOs4f8DF0qal48v/E+yrqynJR2XP38ReAnYDXTkYxjnSTo879J6Eeh4GcfBEucgsGRFxC+A84HPA5vJBpbPiIi9EbEXOAu4APgt2XjCN8seu5JsnOAL+fqn8m0PtoYfAH8D3ELWCnk1sDRfPYEscH5L1n20hWwcA+B9wNOSXgQ+mL8OsyGRL0xjZpY2twjMzBLnIDAzS5yDwMwscQ4CM7PEjal1AQdrypQpMXPmzFqXYWY2oqxatWpzREyttG7EBcHMmTNZuXJlrcswMxtRJD3T3zp3DZmZJc5BYGaWOAeBmVniRtwYQSX79u2jra2N3bt317qUUaNUKjFjxgyKxWKtSzGzKhsVQdDW1sb48eOZOXMmPSeLtKGICLZs2UJbWxuzZs2qdTlmVmWjomto9+7dTJ482SFwiEhi8uTJbmGZJWJUBAHgEDjEfDzN0jFqguBAdu/r4Pltu2nv6Kx1KWZmdSWZINizr4ON23ezr/PQT7u9detWvvSlLx304xYvXszWrVsPeT1mZgcjmSBoaMi6OmIYg6CjY+CLRt1xxx0cccQRh7weM7ODMSo+NTQYXX3enVW4EM/ll1/Or371K+bNm0exWGTcuHFMmzaN1atX89hjj/Hud7+bZ599lt27d3PJJZewbNkyYP90GTt27OC0007jLW95C/fddx/Tp0/ntttuo6mp6ZDXambW26gLgk99+1EeW/9in+WdEeza20GpWKDQcHADoa8/egJXnDGn3/VXXnkla9euZfXq1dxzzz2cfvrprF27tvujl9dffz2TJk1i165dHHfccZx99tlMnjy5x3M8+eST3HjjjXzlK1/hnHPO4ZZbbuH88331QTOrvlEXBAcyHBfmXLhwYY/P33/uc5/j1ltvBeDZZ5/lySef7BMEs2bNYt68eQAce+yxPP3008NQqZnZKAyC/v5z39vewRPPb2fGxGYmjW2sag1jx47tvn3PPfdw11138dOf/pTm5mYWLVpU8fP5hx12WPftQqHArl27qlqjmVmXdAaL8zGCqMIYwfjx49m+fXvFddu2bWPixIk0NzfzxBNPcP/99x/y/ZuZvRyjrkXQn2oOFk+ePJkTTjiBuXPn0tTUxFFHHdW97tRTT+Xaa6+lpaWF1772tRx//PGHfP9mZi+HqvEfcjW1trZG7wvTPP7448yePXvAx0UEj6zbxlETShw1oVTNEkeNwRxXMxsZJK2KiNZK65LpGpJEg1SVFoGZ2UiWTBAASFCF88nMzEa0pIKgQarKmcVmZiNZckHgriEzs54SCwJ3DZmZ9ZZYELhFYGbWW1JBUC+DxePGjQNg/fr1LFmypOI2ixYtovfHZHu7+uqr2blzZ/d9T2ttZkORVBDUW4vg6KOPZsWKFUN+fO8g8LTWZjYUaQVBg6oyxcRll13W43oEn/zkJ/nUpz7FySefzIIFC3jDG97Abbfd1udxTz/9NHPnzgVg165dLF26lJaWFs4999wecw1dfPHFtLa2MmfOHK644gogm8hu/fr1nHTSSZx00klANq315s2bAbjqqquYO3cuc+fO5eqrr+7e3+zZs7nooouYM2cOp5xyiuc0MrNROMXEnZfD849UXHVUewftnQGNB/myf+cNcNqV/a5eunQpl156KR/60IcAuPnmm/nud7/LRz/6USZMmMDmzZs5/vjjede73tXvtYCvueYampubWbNmDWvWrGHBggXd6z796U8zadIkOjo6OPnkk1mzZg0f+chHuOqqq7j77ruZMmVKj+datWoVX/va13jggQeICN74xjfytre9jYkTJ3q6azPrI6kWQbXMnz+fjRs3sn79eh5++GEmTpzItGnT+MQnPkFLSwtvf/vbWbduHRs2bOj3Oe69997uN+SWlhZaWlq61918880sWLCA+fPn8+ijj/LYY48NWM9PfvIT3vOe9zB27FjGjRvHWWedxY9//GPA012bWV+jr0UwwH/uL2zbxeYde3nD9MMP+W6XLFnCihUreP7551m6dCnLly9n06ZNrFq1imKxyMyZMytOP12uUmvhN7/5DZ/5zGd48MEHmThxIhdccMEBn2eg7i9Pd21mvSXVImhQNkZQjXGCpUuXctNNN7FixQqWLFnCtm3bOPLIIykWi9x9990888wzAz7+xBNPZPny5QCsXbuWNWvWAPDiiy8yduxYDj/8cDZs2MCdd97Z/Zj+pr8+8cQT+da3vsXOnTt56aWXuPXWW3nrW996CF+tmY0mo69FMICGsqmoC/301Q/VnDlz2L59O9OnT2fatGmcd955nHHGGbS2tjJv3jxe97rXDfj4iy++mAsvvJCWlhbmzZvHwoULATjmmGOYP38+c+bM4VWvehUnnHBC92OWLVvGaaedxrRp07j77ru7ly9YsIALLrig+zk+8IEPMH/+fHcDmVlFyUxDDbBlxx7Wbd3F7GkTKBaSagwNiaehNhs9PA11rqGKF6cxMxupEguC7LtzwMxsv1ETBIPp4qrm5SpHm5HWZWhmQzcqgqBUKrFly5YDvnk15E2CznqYcKiORQRbtmyhVPIlPc1SMCo+NTRjxgza2trYtGnTgNvtbe9k4/Y9dLzQSKlYGKbqRqZSqcSMGTNqXYaZDYOqBYGk64F3AhsjYu4A2x0H3A+cGxFDmoGtWCwya9asA273yw3buWj5vXzxjxZw+uxpQ9mVmdmoU82uoRuAUwfaQFIB+N/A96pYR7emvBWwa1/HcOzOzGxEqFoQRMS9wAsH2Oy/AbcAG6tVR7mSg8DMrI+aDRZLmg68B7h2ENsuk7RS0soDjQMMpLkxD4K97UN+DjOz0aaWnxq6GrgsIg7473lEXBcRrRHROnXq1CHvsLtFsLdzyM9hZjba1PJTQ63ATfln+6cAiyW1R8S3qrXDQoNoHNPgriEzszI1C4KI6P6Yj6QbgO9UMwS6NBUL7HYQmJl1q+bHR28EFgFTJLUBVwBFgIg44LhAtTQVC+za6yAwM+tStSCIiPcexLYXVKuO3pobC+x0i8DMrNuomGLiYJTcIjAz6yG5IGhq9BiBmVm59IKgWPCnhszMyiQXBO4aMjPrKbkgaG50i8DMrFxyQeCPj5qZ9ZReELhFYGbWQ3JBUPJgsZlZD8kFQVOxwN72Tjp8uUozMyDBIOieitqtAjMzIMEgKHVfk8BBYGYGCQZB1+UqfXaxmVkm2SBw15CZWSa9IGjMXrK7hszMMukFQTGbeXung8DMDEgxCBo9RmBmVi69IPAYgZlZD+kGgbuGzMyABIOg1DVY7BaBmRmQYBA0N2aDxW4RmJllkguC0hi3CMzMyiUXBGMKDTQWGhwEZma55IIAoFRscNeQmVkuySBoaiz4PAIzs1ySQdDcOMZnFpuZ5ZIMAl+lzMxsvySDoKnY4K4hM7NcmkHQWPBgsZlZLs0gcNeQmVm3NIOgcYxbBGZmuTSDoOgTyszMuiQaBO4aMjPrkmQQlDxYbGbWLckgaCoW2NPeSWdn1LoUM7OaSzIImht9lTIzsy5JBoEvV2lmtl+SQVDy5SrNzLolGQRNedeQp5kwM6tiEEi6XtJGSWv7WX+epDX5132SjqlWLb25a8jMbL9qtghuAE4dYP1vgLdFRAvw98B1Vaylh64WgaeiNjODMdV64oi4V9LMAdbfV3b3fmBGtWrpzS0CM7P96mWM4P3Anf2tlLRM0kpJKzdt2vSyd9Y9RuAWgZlZ7YNA0klkQXBZf9tExHUR0RoRrVOnTn3Z+3SLwMxsv6p1DQ2GpBbgH4HTImLLcO3XQWBmtl/NWgSSfhf4JvC+iPjlcO67q2vI5xGYmVWxRSDpRmARMEVSG3AFUASIiGuBvwUmA1+SBNAeEa3VqqecTygzM9uvmp8aeu8B1n8A+EC19j+QYqGBYkHuGjIzow4Gi2ul5GsSmJkBCQdBU7HgKSbMzEg5CBoLPrPYzIyUg6Doq5SZmUHKQdDoMQIzM0g5CDxGYGYGJB4EbhGYmSUcBCUPFpuZAYMMAkmXSJqgzFclPSTplGoXV03NxYJnHzUzY/Atgv8aES8CpwBTgQuBK6tW1TDwYLGZWWawQaD8+2LgaxHxcNmyEcljBGZmmcEGwSpJ/04WBN+TNB7orF5Z1VcqFti9r5POzqh1KWZmNTXYSefeD8wDfh0ROyVNIuseGrG6r1LW3kFzY00vy2BmVlODbRG8CfhFRGyVdD7w18C26pVVfc2+JoGZGTD4ILgG2CnpGOAvgWeAb1StqmFQ8lXKzMyAwQdBe0QEcCbwDxHxD8D46pVVfV2Xq/TZxWaWusF2jm+X9HHgfcBbJRXIrzY2UnVft3jviB7zNjN72QbbIjgX2EN2PsHzwHTg/1atqmHQNVi8c297jSsxM6utQQVB/ua/HDhc0juB3RExoscIui9g764hM0vcYKeYOAf4GfCHwDnAA5KWVLOwavMYgZlZZrBjBH8FHBcRGwEkTQXuAlZUq7Bqa/KnhszMgMGPETR0hUBuy0E8ti51dw15sNjMEjfYFsF3JX0PuDG/fy5wR3VKGh5d5xF4sNjMUjeoIIiIj0k6GziBbLK56yLi1qpWVmVdZxZ7jMDMUjfoSXYi4hbglirWMqyKhQbGNMhjBGaWvAGDQNJ2oNL0nAIiIiZUpaph0lQseIzAzJI3YBBExIieRuJASr44jZnZyP7kz8uVtQg8WGxmaUs6CJrdIjAzSzsISsUCu/Z5jMDM0pZ0EDQVC+z2hWnMLHFpB4G7hszMEg+CYsFnFptZ8tIOgsYCuz1GYGaJSzsIiu4aMjNLOwgaC+zyYLGZJS7pICjlLYKISrNomJmlIekg2H+VMo8TmFm6qhYEkq6XtFHS2n7WS9LnJD0laY2kBdWqpT/Nvm6xmVlVWwQ3AKcOsP404DX51zLgmirWUpEvV2lmVsUgiIh7gRcG2ORM4BuRuR84QtK0atVTSan7cpUOAjNLVy3HCKYDz5bdb8uX9SFpmaSVklZu2rTpkBWwf4zAQWBm6aplEKjCsoof34mI6yKiNSJap06desgKaOq+brGDwMzSVcsgaANeUXZ/BrB+OAto8mCxmVlNg+B24I/zTw8dD2yLiOeGs4DuwWK3CMwsYYO+eP3BknQjsAiYIqkNuAIoAkTEtcAdwGLgKWAncGG1aulPV4vAYwRmlrKqBUFEvPcA6wP4cLX2Pxj++KiZmc8sBjxYbGZpSzsI3DVkZpZ2EBQLotAgDxabWdKSDgJJviaBmSUv6SCA/VNRm5mlKvkgaGpscNeQmSUt+SBoLo5xEJhZ0pIPglKju4bMLG3JB0FTscFBYGZJcxAUCz6PwMyS5iBoLHiMwMyS5iAojvEUE2aWNAdBY4O7hswsaQ4Cn1BmZolzEORBkM2KbWaWnuSDoNRYIAL2tHfWuhQzs5pIPgh8uUozS13yQdDsC9ibWeKSD4KSL1dpZolLPgjcNWRmqXMQ+HKVZpY4B4EvYG9miXMQeLDYzBLnICi6a8jM0uYgaPRgsZmlzUHgj4+aWeKSD4KSB4vNLHHJB8FhYxpokMcIzCxdyQeBpGwGUrcIzCxRyQcB5JerdIvAzBLlICAbJ3AQmFmqHATgriEzS5qDgGwqarcIzCxVDgLyriG3CMwsUQ4CssFif3zUzFLlIGD/BezNzFLkICALAp9ZbGapchDgriEzS1tVg0DSqZJ+IekpSZdXWH+4pG9LeljSo5IurGY9/fHHR80sZVULAkkF4IvAacDrgfdKen2vzT4MPBYRxwCLgM9KaqxWTf3pOrM4IoZ712ZmNVfNFsFC4KmI+HVE7AVuAs7stU0A4yUJGAe8ALRXsaaKSsUCnQF7OzqHe9dmZjVXzSCYDjxbdr8tX1buC8BsYD3wCHBJRPR5N5a0TNJKSSs3bdp0yAvtviaBu4fMLEHVDAJVWNa77+UdwGrgaGAe8AVJE/o8KOK6iGiNiNapU6ce6jpp9nWLzSxh1QyCNuAVZfdnkP3nX+5C4JuReQr4DfC6KtZUkS9XaWYpq2YQPAi8RtKsfAB4KXB7r23+AzgZQNJRwGuBX1expopKvlylmSVsTLWeOCLaJf0Z8D2gAFwfEY9K+mC+/lrg74EbJD1C1pV0WURsrlZN/ekaI/C5BGaWoqoFAUBE3AHc0WvZtWW31wOnVLOGwejqGvLZxWaWIp9ZjD81ZGZpcxBQNljsriEzS5CDAI8RmFnaHAS4a8jM0uYgoGyw2C0CM0uQgwA4bEwDEux2i8DMEuQgACT5KmVmliwHQc5BYGapchDkSsUCu/Z6GmozS4+DIJddnGbYL4VgZlZzDoJcc6MvV2lmaXIQ5EoeIzCzRDkIctlgsccIzCw9DoJcU7Hg8wjMLEkOglxTY4GdHiw2swQ5CHJNjf74qJmlqaoXphlJmooFXty1j8//4EmmT2zi6COamH5EE79zeIliwXlpZqOXgyC3cNYkblu9js9+/5c9ljcIjppQYvoRTRx1eInJYxuZNLaRyeMOY/LYxuxrXCOTxh5GqdiAEBLZV367QULky6TavEAzs36kEwS/+C7825/3u/odwDuaIZqCjoD2TuiIoL0T2juD9s3QsTGI6CQiuh8nAhHsAfYSZcuy75Td7lre0H07v6+sS2r/0uxZOntslS0bSLa3hu69duZ77ix7jih7jkrL9u+dPsvK7/dcsn/N/jp6Pnf5Xvs+otJ+Ku+h76O69lJ+zOlx1MqfLfqsKT/uvX9iVNx2wFJ6blxx/31fTfS6Xfbz6Of5o8/hOfBx7f1z7K+G/hy49srPdaD7A++55+/R/t+n6PO6yn93u356+7cd3Gss30d/9VX6uxl4ed/XVL5tf78blX70//Gqc3nzH//dANUPTTpBMG4qvPqkA26mgDFEdmAi/2WK/T+q7I0V9rQHe9o72dPeye72Tva0ZwGS/TAj+wFHzzf3rjfnzu510BkNdObriK4tyn6BIx+3iACVvQVXeiOIrl+xzvy19H2+rtdS/utX/t6Trc7Xdr0LBUTZb6X6vF2Vr+t9vLqCo28A7X9Qz7etCk/a/9qu4xIQEhFdf/Jdy9Wjjh51dlUTPf8s+3vj7PNG0vfduILyN/VKgdrrzaP8ZzHoZ66s53Gu8CbV42de+Y2+/JFQ9qPqUae6iw2Vb12+be9/BQ7cMu7xO1r+iAjKf0fL3+57/4vW+3crDtQij0pv733/pehTW/Rc33v7XlXtf+6yvxX12bqv0uTfPcAWQ5NOEEw/Nvs6BBqApvzLzGyk8yiomVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOMWgzo6sH5I2Ac8M8eFTgM2HsJxDybUNTT3XBvVdn2sbmpFa2ysjYmqlFSMuCF4OSSsjorXWdVTi2oamnmuD+q7PtQ3NaKzNXUNmZolzEJiZJS61ILiu1gUMwLUNTT3XBvVdn2sbmlFXW1JjBGZm1ldqLQIzM+vFQWBmlrhkgkDSqZJ+IekpSZfXup5ykp6W9Iik1ZJW1riW6yVtlLS2bNkkSd+X9GT+fWId1fZJSevyY7da0uIa1fYKSXdLelzSo5IuyZfX/NgNUFvNj52kkqSfSXo4r+1T+fJ6OG791Vbz41ZWY0HSzyV9J78/pOOWxBiBpALwS+APgDbgQeC9EfFYTQvLSXoaaI2Imp+kIulEYAfwjYiYmy/7P8ALEXFlHqITI+KyOqntk8COiPjMcNfTq7ZpwLSIeEjSeGAV8G7gAmp87Aao7RxqfOwkCRgbETskFYGfAJcAZ1H749ZfbadSB79zAJL+HGgFJkTEO4f6t5pKi2Ah8FRE/Doi9gI3AWfWuKa6FBH3Ai/0Wnwm8PX89tfJ3kSGXT+11YWIeC4iHspvbwceB6ZTB8dugNpqLjI78rvF/Cuoj+PWX211QdIM4HTgH8sWD+m4pRIE04Fny+63USd/CLkA/l3SKknLal1MBUdFxHOQvakAR9a4nt7+TNKavOuoJt1W5STNBOYDD1Bnx65XbVAHxy7v3lgNbAS+HxF1c9z6qQ3q4LgBVwN/CXSWLRvScUslCFRhWd0kO3BCRCwATgM+nHeB2OBcA7wamAc8B3y2lsVIGgfcAlwaES/WspbeKtRWF8cuIjoiYh4wA1goaW4t6qikn9pqftwkvRPYGBGrDsXzpRIEbcAryu7PANbXqJY+ImJ9/n0jcCtZV1Y92ZD3M3f1N2+scT3dImJD/sfaCXyFGh67vB/5FmB5RHwzX1wXx65SbfV07PJ6tgL3kPXB18Vx61JeW50ctxOAd+XjizcBvy/pnxnicUslCB4EXiNplqRGYClwe41rAkDS2HwAD0ljgVOAtQM/atjdDvxJfvtPgNtqWEsPXb/0ufdQo2OXDyx+FXg8Iq4qW1XzY9dfbfVw7CRNlXREfrsJeDvwBPVx3CrWVg/HLSI+HhEzImIm2fvZDyPifIZ63CIiiS9gMdknh34F/FWt6ymr61XAw/nXo7WuDbiRrLm7j6wl9X5gMvAD4Mn8+6Q6qu2fgEeANfkfwbQa1fYWsu7GNcDq/GtxPRy7AWqr+bEDWoCf5zWsBf42X14Px62/2mp+3HrVuQj4zss5bkl8fNTMzPqXSteQmZn1w0FgZpY4B4GZWeIcBGZmiXMQmJklzkFgNowkLeqaKdKsXjgIzMwS5yAwq0DS+flc9KslfTmffGyHpM9KekjSDyRNzbedJ+n+fBKyW7smIZP0XyTdlc9n/5CkV+dPP07SCklPSFqen/lrVjMOArNeJM0GziWbDHAe0AGcB4wFHopsgsAfAVfkD/kGcFlEtJCdcdq1fDnwxYg4Bngz2VnRkM3+eSnwerIzy0+o8ksyG9CYWhdgVodOBo4FHsz/WW8im7yrE/iXfJt/Br4p6XDgiIj4Ub7868C/5vNHTY+IWwEiYjdA/nw/i4i2/P5qYCbZRU/MasJBYNaXgK9HxMd7LJT+ptd2A83PMlB3z56y2x3479BqzF1DZn39AFgi6Ujovg7sK8n+Xpbk2/wR8JOI2Ab8VtJb8+XvA34U2Xz/bZLenT/HYZKah/NFmA2W/xMx6yUiHpP012RXjWsgm+30w8BLwBxJq4BtZOMIkE33e23+Rv9r4MJ8+fuAL0v6u/w5/nAYX4bZoHn2UbNBkrQjIsbVug6zQ81dQ2ZmiXOLwMwscW4RmJklzkFgZpY4B4GZWeIcBGZmiXMQmJkl7j8BfTVjJSYY6q0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_model_performance(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9K7CgkLGaMA2",
    "outputId": "d8e0c686-342f-477a-efd6-b004f82f4517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Training data: \n",
      "14/14 [==============================] - 0s 21ms/step - loss: 7.3508 - binary_accuracy: 0.4967\n",
      "{'loss': 7.350840091705322, 'binary_accuracy': 0.49671250581741333}\n",
      "tf.Tensor(\n",
      "[[837   0]\n",
      " [836   0]], shape=(2, 2), dtype=int32)\n",
      "Generating three false positives...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a17a6cd716ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c3d2d45d9140>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_train, X_val, X_test, y_train, y_val, y_test, threshold, pictures)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpictures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating Training data: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mevaluate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpictures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpictures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating Validation data: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c3d2d45d9140>\u001b[0m in \u001b[0;36mevaluate_dataset\u001b[0;34m(model, X, y, threshold, pictures)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfalse_positives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mrandi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mprint_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating three false negatives...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
