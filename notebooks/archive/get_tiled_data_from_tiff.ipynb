{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDrive\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
      "\u001b[K    100% |████████████████████████████████| 993kB 3.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client>=1.2 (from PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/fc/98045b8c5e0ba12929d423e9ff6b742951bb846707539b18f19b27c6ddc3/google_api_python_client-1.12.8-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client>=4.0.0 (from PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/a9/4f25a14d23f0786b64875b91784607c2277eff25d48f915e39ff0cff505a/oauth2client-4.1.3-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 7.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from PyDrive) (3.13)\n",
      "Collecting httplib2<1dev,>=0.15.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ad/d9d9331850ea5bd4f5cb8c650c0bfa119a4abd6b0ad7c45b6506bc979fc0/httplib2-0.18.1-py3-none-any.whl (95kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 7.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth>=1.16.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/90/58d541b95c501063dc3cee96e2ae87660e264f97e8cbb0887cffb627211b/google_auth-1.25.0-py2.py3-none-any.whl (116kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 7.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six<2dev,>=1.13.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting google-auth-httplib2>=0.0.3 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/4e/992849016f8b0c27fb604aafd0a7a724db16128906197bd1245c6f18e6a1/google_auth_httplib2-0.0.4-py2.py3-none-any.whl\n",
      "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/0c/60d82c077998feb631608dca3cc1fe19ac074e772bf0c24cf409b977b815/uritemplate-3.0.1-py2.py3-none-any.whl\n",
      "Collecting google-api-core<2dev,>=1.21.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/fb/2ec182926a23b2e13d07680ba667599939059abf62a16fa2689d22de47f8/google_api_core-1.25.1-py2.py3-none-any.whl (92kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 8.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.0.5 (from oauth2client>=4.0.0->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 5.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.7 (from oauth2client>=4.0.0->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa>=3.1.4 (from oauth2client>=4.0.0->PyDrive)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/87/dc7a6ebf0afbc602548627fa48e9c1147fa187233bf71d4c51c76a2cfb27/rsa-4.7-py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/72/8df2e0dc991f1a1d2c6869404e7622e8ee50d80bff357dbb57c3df70305b/cachetools-4.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (40.6.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.21.0)\n",
      "Requirement already satisfied: pytz in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.7)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/74/3956721ea1eb4bcf7502a311fdaa60b85bd751de4e57d1943afe9b334141/googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 3.9MB/s a 0:00:011\n",
      "\u001b[?25hCollecting protobuf>=3.12.0 (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/dd/5c5d156ee1c4dba470d76dac5ae57084829b4e17547f28e9f636ce3fa54b/protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 2.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.11.29)\n",
      "Building wheels for collected packages: PyDrive\n",
      "  Running setup.py bdist_wheel for PyDrive ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /sailhome/mhelabd/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
      "Successfully built PyDrive\n",
      "Installing collected packages: httplib2, pyasn1, pyasn1-modules, cachetools, rsa, six, google-auth, google-auth-httplib2, uritemplate, protobuf, googleapis-common-protos, google-api-core, google-api-python-client, oauth2client, PyDrive\n",
      "  Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "Successfully installed PyDrive-1.3.1 cachetools-4.2.1 google-api-core-1.25.1 google-api-python-client-1.12.8 google-auth-1.25.0 google-auth-httplib2-0.0.4 googleapis-common-protos-1.52.0 httplib2-0.18.1 oauth2client-4.1.3 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7 six-1.15.0 uritemplate-3.0.1\n",
      "Requirement already satisfied: pandas in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: six>=1.5 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.15.0)\n",
      "Collecting rasterio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/ed/aa7cc593dbcb974f80ca0a15967d44abc820dbeb063e01478c95adcca156/rasterio-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (19.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 19.1MB 453kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cligj>=0.5 (from rasterio)\n",
      "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from rasterio) (2018.11.29)\n",
      "Requirement already satisfied: numpy in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from rasterio) (1.15.4)\n",
      "Requirement already satisfied: click<8,>=4.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from rasterio) (7.0)\n",
      "Requirement already satisfied: attrs in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from rasterio) (18.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from snuggs>=1.4.1->rasterio) (2.3.0)\n",
      "Installing collected packages: cligj, click-plugins, snuggs, affine, rasterio\n",
      "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.1 rasterio-1.2.0 snuggs-1.4.7\n",
      "Requirement already satisfied: matplotlib in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.15.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.7.5)\n",
      "Requirement already satisfied: six in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /atlas/u/mhelabd/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.6.3)\n",
      "Collecting shapely\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/f8/db4d3426a1aba9d5dfcc83ed5a3e2935d2b1deb73d350642931791a61c37/Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "Successfully installed shapely-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive\n",
    "!pip install pandas\n",
    "!pip install rasterio\n",
    "!pip install matplotlib\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from os import listdir, path\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "# Try to load saved client credentials\n",
    "gauth.LoadCredentialsFile(\"mycreds.txt\")\n",
    "if gauth.credentials is None:\n",
    "    # Authenticate if they're not there\n",
    "    gauth.LocalWebserverAuth()\n",
    "elif gauth.access_token_expired:\n",
    "    # Refresh them if expired\n",
    "    gauth.Refresh()\n",
    "else:\n",
    "    # Initialize the saved creds\n",
    "    gauth.Authorize()\n",
    "# Save the current credentials to a file\n",
    "gauth.SaveCredentialsFile(\"mycreds.txt\")\n",
    "\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index        lat        lon     x    y      prob prediction   shape\n",
      "0      0  23.796287  90.316715  1043  518  0.564438     zigzag  zigzag\n",
      "1      1  23.940202  90.043026    78  149  0.692853     zigzag  zigzag\n",
      "2      2  25.021253  89.309124   636  327  0.499505        fck     fck\n",
      "3      3  25.308184  89.550603    97   85  0.342437        fck  zigzag\n",
      "4      4  22.561670  92.007151   145  175  0.922128     zigzag  zigzag\n"
     ]
    }
   ],
   "source": [
    "# set params\n",
    "tile_height, tile_length = (64, 64)\n",
    "bands_to_read = None # ['B4', 'B3', 'B2'] # set to None to read all bands\n",
    "examples_per_save_file = 1000\n",
    "save_path = '/atlas/u/mhelabd/data/kiln-scaling/tiles/'\n",
    "composite_file_name = 'bangladesh_all_bands_final'\n",
    "composite_save_path = '/atlas/u/mhelabd/data/kiln-scaling/composites/'\n",
    "\n",
    "# resources\n",
    "kilns = pd.read_csv(\"../data/bangladesh_kilns.csv\")\n",
    "all_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B8', 'B9', 'B10', 'B11', 'B12']\n",
    "band_dict = dict(zip(all_bands, range(1, len(all_bands) + 1)))\n",
    "\n",
    "print(kilns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 files\n",
      "title: bangladesh_all_bands_final-0000000000-0000000000.tif, id: 1ZHtyKejLTVvFo5s1Ui--sA_RqKBtfZlZ\n",
      "title: bangladesh_all_bands_final-0000000000-0000006656.tif, id: 1GlKU0_kZEaisJ8sBWGsl7VNg9pwsPD8Z\n",
      "title: bangladesh_all_bands_final-0000000000-0000013312.tif, id: 1Wm1kJeH2zQ42bNEuqDbSLcR_vP-KEu6_\n",
      "title: bangladesh_all_bands_final-0000000000-0000019968.tif, id: 1RkLg2pzmr9QkVg8NmfPhKVbPGAtxkfKH\n",
      "title: bangladesh_all_bands_final-0000000000-0000026624.tif, id: 1YCQxQ6WzZQTwpEKY7IeW1lWbCBYcUN2l\n"
     ]
    }
   ],
   "source": [
    "file_list = drive.ListFile({'q': \"title contains '\" + composite_file_name + \"'\"}).GetList()\n",
    "print(\"Found \" + str(len(file_list)) + \" files\")\n",
    "file_list = sorted(file_list, key=lambda file: file['title'])\n",
    "for file in file_list[:5]:\n",
    "  print('title: %s, id: %s' % (file['title'], file['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image grid columns: 8\n",
      "Number of image grid rows: 10\n"
     ]
    }
   ],
   "source": [
    "# calculate image grid\n",
    "first_x_coord = file_list[0]['title'].split(\".\")[0].split(\"-\")[1]\n",
    "first_y_coord = file_list[0]['title'].split(\".\")[0].split(\"-\")[2]\n",
    "num_image_cols = len([x for x in file_list if x['title'].split(\".\")[0].split(\"-\")[1] == first_x_coord])\n",
    "num_image_rows = len([x for x in file_list if x['title'].split(\".\")[0].split(\"-\")[2] == first_y_coord])\n",
    "print(\"Number of image grid columns:\", num_image_cols)\n",
    "print(\"Number of image grid rows:\", num_image_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "with open(\"../data/countries.geojson\", \"r\") as countries_geojson:\n",
    "    country_dict = json.load(countries_geojson)[\"features\"]\n",
    "for obj in country_dict:\n",
    "    name = obj['properties']['ADMIN']\n",
    "    if name == \"Bangladesh\":\n",
    "        coords = obj['geometry'][\"coordinates\"]\n",
    "flat_coords = []\n",
    "for sublist in coords:\n",
    "    for coord in sublist:\n",
    "        for c in coord:\n",
    "            flat_coords.append(c)\n",
    "\n",
    "bangladesh_geo = Polygon(flat_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open DatasetReader name='data/b_composites/bangladesh_all_bands_final-0000000000-0000000000.tif' mode='r'>\n",
      "BoundingBox(left=88.02178244056496, bottom=26.02563108539713, right=88.61970109367492, top=26.623549738507084)\n"
     ]
    }
   ],
   "source": [
    "# print(datasets[0])\n",
    "# print(datasets[0].bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing variables\n",
    "num_tiles_dropped = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands_and_bounds_from_file(file, band_names=None):\n",
    "    print(\"Starting file \" + file['title'])\n",
    "    composite_file_path = composite_save_path + file['title']\n",
    "    if path.exists(composite_file_path):\n",
    "        print(\"File already downloaded.\")\n",
    "    else:\n",
    "        print(\"Downloading file...\")\n",
    "        # download the file\n",
    "        download_file = drive.CreateFile({'id': file['id']})\n",
    "        file.GetContentFile(composite_file_path)\n",
    "    \n",
    "    # open file with rasterio\n",
    "    print(\"Reading file...\")\n",
    "    dataset = rasterio.open(composite_file_path)\n",
    "    if band_names is None: # get all bands\n",
    "        bands = dataset.read()\n",
    "    else:\n",
    "        # TODO refactor using np.index_select\n",
    "        bands = []\n",
    "        for idx, band_name in enumerate(band_names):\n",
    "            band_index = band_dict[band_name]\n",
    "            bands += [dataset.read(band_index)]\n",
    "        bands = np.array(bands)\n",
    "    print(\"Done processing file\")\n",
    "    return bands, dataset.bounds\n",
    "\n",
    "def get_data_given_pixels(ds_bounds, bands, start_row, start_col, contains_kiln):\n",
    "    global num_tiles_dropped\n",
    "    \n",
    "    num_bands, ds_height, ds_length = bands.shape\n",
    "    tile_top = ds_bounds.top - (start_row / ds_height) * (ds_bounds.top - ds_bounds.bottom)\n",
    "    tile_bottom = ds_bounds.top - ((start_row + tile_height) / ds_height) * (ds_bounds.top - ds_bounds.bottom)\n",
    "    tile_left = ds_bounds.left + (start_col / ds_length) * (ds_bounds.right - ds_bounds.left)\n",
    "    tile_right = ds_bounds.left + ((start_col + tile_length) / ds_length) * (ds_bounds.right - ds_bounds.left)\n",
    "    tile_coordinates = [[tile_left, tile_top], [tile_right, tile_top], [tile_right, tile_bottom], [tile_left, tile_bottom]]\n",
    "#     print(\"top\", tile_top, \"bottom\", tile_bottom, \"left\", tile_left, \"right\", tile_right)\n",
    "    if not contains_kiln:\n",
    "        for point in [Point([c[0], c[1]]) for c in tile_coordinates]:\n",
    "            if not bangladesh_geo.contains(point):\n",
    "                num_tiles_dropped += 1\n",
    "                return None\n",
    "    return bands[:, start_row : start_row + tile_height, start_col : start_col + tile_length]\n",
    "\n",
    "# def add_example(ex_data, save_index, list_to_add, is_positive):\n",
    "def add_example(ex_data, save_index, counter, examples, is_positive):\n",
    "    examples[counter] = ex_data\n",
    "    new_counter = counter + 1\n",
    "    # save files if needed\n",
    "    if new_counter == examples_per_save_file:\n",
    "        filename = save_path + (\"pos\" if is_positive else \"neg\") + \"_examples_\" + str(save_index) + \".csv\"\n",
    "        print(\"Saving file\", filename)\n",
    "        np.savetxt(filename, examples.flatten(), delimiter=\",\")\n",
    "        print(\"Finished saving file\")\n",
    "        save_index += 1\n",
    "        new_counter = 0\n",
    "    return new_counter, save_index\n",
    "\n",
    "def get_kiln_tiles(bounds, num_rows, num_cols):\n",
    "    kilns_in_image = kilns.loc[(kilns['lat'] >= bounds['bottom']) & (kilns['lat'] <= bounds['top']) \n",
    "        & (kilns['lon'] >= bounds['left']) & (kilns['lon'] <= bounds['right'])]\n",
    "    \n",
    "    tiles = set() # set of tuples of (tile_row, tile_col)\n",
    "    for index, kiln in kilns_in_image.iterrows():\n",
    "        lon_percent = 1 - (kiln['lon'] - bounds['left']) / (bounds['right'] - bounds['left'])\n",
    "        row_index = int(num_rows * lon_percent)\n",
    "        \n",
    "        lat_percent = 1 - (kiln['lat'] - bounds['bottom']) / (bounds['top'] - bounds['bottom'])\n",
    "        col_index = int(num_cols * lat_percent)\n",
    "        tiles.add((row_index, col_index))\n",
    "    return tiles\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all bands from dataset data/b_composites/bangladesh_all_bands_final-0000000000-0000000000.tif\n",
      "time to read bands: 22.185380935668945\n",
      "Reading all bands from dataset data/b_composites/bangladesh_all_bands_final-0000000000-0000006656.tif\n",
      "time to read bands: 22.828599214553833\n",
      "Reading all bands from dataset data/b_composites/bangladesh_all_bands_final-0000006656-0000000000.tif\n",
      "time to read bands: 23.33644390106201\n",
      "Reading all bands from dataset data/b_composites/bangladesh_all_bands_final-0000006656-0000006656.tif\n",
      "time to read bands: 21.856069087982178\n",
      "Data shape: (13, 6656, 6656)\n"
     ]
    }
   ],
   "source": [
    "# data_pixels = []\n",
    "# for ds in datasets:\n",
    "#     data_pixels += [get_bands_from_dataset(ds, band_names=bands_to_read)]\n",
    "    \n",
    "# print(\"Data shape:\", data_pixels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples shape: (1000, 13, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "pos_save_index, neg_save_index = 0, 0\n",
    "pos_counter, neg_counter = 0, 0\n",
    "\n",
    "pos_x_examples = np.zeros([examples_per_save_file, len(all_bands) if bands_to_read is None else len(bands_to_read), tile_height, tile_length])\n",
    "neg_x_examples = np.zeros([examples_per_save_file, len(all_bands) if bands_to_read is None else len(bands_to_read), tile_height, tile_length])\n",
    "print(\"Examples shape:\", pos_x_examples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f2f71a4eb342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "file_list = file_list[:1] # testing purposes\n",
    "\n",
    "total_start_time = time.time()\n",
    "for index, file in enumerate(file_list):\n",
    "    file_start_time = time.time()\n",
    "    bands, ds_bounds = get_bands_and_bounds_from_file(file, band_names=bands_to_read)\n",
    "    \n",
    "    file_in_country = False\n",
    "    file_coordinates = [[ds_bounds.left, ds_bounds.top], [ds_bounds.right, ds_bounds.top], [ds_bounds.right, ds_bounds.bottom], [ds_bounds.left, ds_bounds.bottom]]\n",
    "    for point in [Point([c[0], c[1]]) for c in tile_coordinates]:\n",
    "        if bangladesh_geo.contains(point):\n",
    "            file_in_country = True\n",
    "    \n",
    "    if file_in_country:\n",
    "        num_bands, ds_height, ds_length = bands.shape\n",
    "        num_rows = ds_height // tile_height\n",
    "        num_cols = ds_length // tile_length\n",
    "\n",
    "        bounds = {\n",
    "            \"bottom\": ds_bounds.bottom,\n",
    "            \"top\": ds_bounds.top,\n",
    "            \"left\": ds_bounds.left,\n",
    "            \"right\": ds_bounds.right\n",
    "        }\n",
    "\n",
    "        row_px_excess, col_px_excess = None, None\n",
    "        percent_row_excess, percent_col_excess = None, None\n",
    "\n",
    "        if index % num_image_cols == num_image_cols - 1: # rightmost column\n",
    "            # calculate excess col pixels\n",
    "            col_px_excess = ds_length % tile_length\n",
    "            bounds[\"right\"] -= col_px_excess / ds_length * (ds.bounds.right - ds.bounds.left)\n",
    "\n",
    "        if index // num_image_cols == num_image_rows - 1: # last row\n",
    "            # calculate excess row pixels\n",
    "            row_px_excess = ds_height % tile_height\n",
    "            bounds[\"bottom\"] += row_px_excess / ds_height * (ds.bounds.top - ds.bounds.bottom)\n",
    "\n",
    "        kiln_tiles = get_kiln_tiles(bounds, num_rows, num_cols)\n",
    "        print(\"Num tiles with kilns:\", len(kiln_tiles))\n",
    "        print(kiln_tiles)\n",
    "\n",
    "        print(\"Tiling dataset...\")\n",
    "        for tile_idx_row in range(0, num_rows):\n",
    "            px_row = tile_idx_row * tile_height\n",
    "            for tile_idx_col in range(0, num_cols):\n",
    "                px_col = tile_idx_col * tile_length\n",
    "                if (tile_idx_row, tile_idx_col) in kiln_tiles:\n",
    "                    data = get_data_given_pixels(ds_bounds, bands, px_row, px_col, True)\n",
    "                    pos_counter, pos_save_index = add_example(data, pos_save_index, pos_counter, pos_x_examples, True)\n",
    "                else:\n",
    "                    data = get_data_given_pixels(ds_bounds, bands, px_row, px_col, False)\n",
    "                    if data is not None:\n",
    "                        neg_counter, neg_save_index = add_example(data, neg_save_index, neg_counter, neg_x_examples, False)\n",
    "        print(\"Total tiles dropped (outside country):\", num_tiles_dropped)\n",
    "        print(\"Total tiles kept:\", str(num_rows * num_cols - num_tiles_dropped))\n",
    "        num_tiles_dropped = 0\n",
    "        print(\"Finished file in\", time.time() - file_start_time, \"\\n\")\n",
    "print(\"Finished \" + str(len(file_list)) + \" files in: \" + str(time.time() - total_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_x_examples[12])\n",
    "print(tile_idx_row, tile_idx_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
